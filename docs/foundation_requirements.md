# RiskOps Demo Stack – Foundation & Requirements

## 1. Current Baseline Audit
- **FastAPI monolith**: `app/main.py` serves `/payment`, `/transaction/{id}`, `/stats`, `/admin/reset`, and mounts the built `frontend-app/dist` React experience at `/demo`. All reads/writes flow through a single FastAPI process backed by SQLite.
- **Data layer**: The `Transaction` ORM (UUID, card number, amount, merchant, status, risk flag, timestamps) is powered by SQLAlchemy 2.0 + SQLite with tables created via `Base.metadata.create_all`.
- **Risk logic**: `app/utils.py` provides a lightweight, amount-driven heuristic with randomness. No external feature store, queue, or asynchronous processing exists yet.
- **Frontend**: React/Vite UI (served via standalone dev server or the bundled `frontend-app/dist` assets) lets users submit payments, fetch transaction details, and view stats without depending on the backend container for build tooling.
- **DevOps posture**: A single `Dockerfile` builds the app, but there is no Docker Compose definition, seed data process, CI/CD workflow, observability integration, or browser regression suite. Redis/Postgres/worker components are not implemented.

## 2. Data Models & Contracts
| Model | Purpose | Key Fields | Notes |
| --- | --- | --- | --- |
| `Transaction` | Persist each payment request and outcome | `id`, `card_number`, `amount`, `currency`, `merchant`, `status`, `risk_flag`, `created_at` | Needs new attributes (`currency`, `channel`, `device_id`) to support richer features. |
| `RiskDecision` | Snapshot returned by the risk engine | `transaction_id`, `status`, `score`, `reason_code`, `explanations` | Generated by FastAPI, logged for auditability, and returned to the client. |
| `DecisionAudit` | Ops-facing audit trail | `id`, `transaction_id`, `inputs_snapshot`, `rules_triggered`, `latency_ms`, `created_at` | Best stored in Postgres JSONB; exposed via `/audit/{transaction_id}`. |
| `FeatureCacheEntry` | Hot feature data in Redis | `cache_key`, `value`, `ttl`, `last_refreshed_at` | Maintained by a background worker so the API can reuse cached signals. |
| `StatsSnapshot` | Payload for `/stats` and dashboards | `total`, `approved`, `declined`, `approval_rate`, `avg_amount`, `p95_latency` | Metrics will be aggregated centrally instead of ad-hoc SQL queries. |

> These models drive both the Pydantic schemas and the Postgres/Redis structures. Alembic migrations and automated tests will keep them in sync in later phases.

## 3. Target Stack Versions
| Layer | Technology | Target Version | Rationale |
| --- | --- | --- | --- |
| Runtime | Python | 3.11.x | Matches the existing repo and remains LTS-friendly. |
| API | FastAPI | 0.111.x | Latest stable release with robust docs and testing utilities. |
| ORM | SQLAlchemy | 2.0.x | Already adopted; will extend with Alembic migrations. |
| Database | PostgreSQL | 15.x | Enterprise-standard with JSONB, partitioning, and tooling. |
| Cache | Redis | 7.x | Supports feature caching, rate limiting, and queue semantics. |
| Worker | RQ or Celery | Latest stable | Handles async feature refresh, stats aggregation, and seeding. |
| Frontend | Node.js 20 + Vite + React 18 | Modern DX, type safety, and Playwright compatibility. |
| Testing | Pytest, Playwright 1.44+, Vitest | Cover API/worker units, browser E2E, and frontend logic respectively. |
| Orchestration | Docker Compose v2 | One command to start API, DB, Redis, worker, and frontend. |
| CI/CD | GitHub Actions (`ubuntu-22.04`), Jenkins LTS | Demonstrate both cloud-native and on-premise pipelines. |

## 4. Architecture Draft
```
          +---------------------+
          |   Demo Frontend     |
          | (React/Vite static) |
          +----------+----------+
                     |
                     | HTTPS / REST
                     v
 +-------------------+-------------------+
 |         FastAPI Risk API              |
 |  - Auth & validation (Pydantic)      |
 |  - Scoring/adjudication endpoints    |
 |  - Audit & stats APIs                |
 +----+---------------+------------------+
      |               |
      | gRPC/Redis    | SQL (async)
      v               v
+-----------+   +---------------------+
| Redis 7   |   | Postgres 15         |
| Feature   |   | transactions, audit |
| Cache     |   | stats materialized  |
+-----------+   +--------------+------+
      ^                       |
      | pub/sub               | CDC / triggers
      |                       v
+-----+-------------------------------+
| Background Worker (Celery/RQ)       |
| - Feature refresh jobs              |
| - Stats aggregation                 |
| - Seed / synthetic data generator   |
+-------------------------------------+
```
- Playwright/Selenium in CI will spin up the Compose stack, drive the frontend, and assert API/DB/UI health.
- Docker Compose will manage networks, volumes, environment files, and run `seed_data.py` to warm Postgres/Redis.
- GitHub Actions pipeline: `lint → pytest → frontend build/test → docker compose config check → Playwright smoke`. Jenkinsfile will mirror the same stages for on-prem audiences.

## 5. Next Steps for Phase 2
1. Carve FastAPI into internal modules (Scoring, Audit, Feature Cache, Admin) with well-defined interfaces.
2. Design Alembic migrations plus Redis key conventions so transactions, audits, and cached features stay consistent.
3. Draft the Docker Compose service list alongside `.env.example` to support the upcoming implementation work.
